CSC D84 - Artificial Intelligence, Winter 2013

Assignment 5 - Neural Networks for OCR

This assignment is worth:

15 AIUs (Artificial Intelligence Units)
toward the 40% assignment component of your final
mark.

________________________________________________

Student Name (last, first): Syed Jaudat

Student number: 997054100	

UTORid: syedjaud

READ THIS AND SIGN YOUR NAME AT THE END:

 I certify that I have read the UTSC code on academic
honesty and plaguarism. All work submitted as part
of this assignment is my own.

	Signed: Jaudat Syed


(-5 marks for failing to provide the identifying
 information requested above)
________________________________________________

Answer the following questions. Be concise and clear
but explain carefully when needed.

Note: Empirically, I have had success with the following parameters:

    Learning rates in [2,6], threshold in [.01, .05] for 1-layer
     networks

    Learninng rates in [.25,10], threshold in [.01, .05] for 2-layer
     networks

    For 2-layer networks, I have seen good results with 15-30 hidden
     units

    You will have to try and see what works best for each network
     architecture. 

1 .- (2.5 marks) Train a 1-layer network using the Logistic activation
               function. 

		Report the learning rate used: 2
		Report the threshold used: 0.02

		Train the network with 3 different random seeds,
		for each seed report:

		List of seeds used:  1562, 1790, 3380

		Average classification accuracy on training set:
		 1562: 91.7342401256
		 1790: 92.3620193565
		 3380: 89.6678001569
		Average classification accuracy on testing set:
		 1562: 88.7033945465
		 1790: 90.2058987201
		 3380: 87.8686700056

		Save a screenshot of the trained network, call your
		file:

		 	1layer-­logistic-­final.jpg 

2 .- (2.5 marks) Repeat the process above but using a 1-layer network
		with hyperbolic tangent activation function.

		Report the learning rate used: 5
		Report the threshold used: 0.05

		For the 3 random seeds report: 

		List of seeds used: 1562, 1790, 3380

		Average classification accuracy on training set:
		1562: 91.6034527858
		1790: 89.3800680094
		3380: 90.7664138111
		Average classification accuracy on testing set:
		1562: 88.7033945465
		1790: 86.4774624374
		3380: 88.592097941

		Save a screenshot of the trained network, call your
		file:

			1layer-tanh-final.jpg

3 .- (2.5 marks) Repeat the process above using a 2-layer network
		with hyperbolic tangent activation function.

		Report the learning rate used: 0.25
		Report the threshold used: 0.05
		Number of hidden units: 15

		For the 3 random seeds report: 1562, 1790, 3380

		List of seeds used:

		Average classification accuracy on training set:
		1562: 92.4928066963
		1790: 92.100444677
		3380: 91.6557677217
		Average classification accuracy on testing set:
		1562: 90.0946021146
		1790: 88.4808013356
		3380: 89.2598775737
		Save a screenshot of the trained network, call your
		file:
			
			2layer-tanh-final.jpg

4 .- (2.5 marks) Repeat the process above using a 2-layer network
		with logistic activation function.

		Report the learning rate used: 7
		Report the threshold used: 0.03
		Number of hidden units: 15

		For the 3 random seeds report: 

		List of seeds used: 1562, 1790, 3380

		Average classification accuracy on training set:
		1562: 
		1790: 
		3380:
		Average classification accuracy on testing set:
		1562: 
		1790: 
		3380:
		Save a screenshot of the trained network, call your
		file:
		
			2layer-logistic-final.jpg

5 .- (5 marks) Which network architecture (number of layers/type of
	       activation function) performs best, and why?

		Here you want to discuss in terms of classification
		accuracy, but also consider training time, ease to
		set the network parameters (learning rate and threshold,
		number of hidden units if applicable), and whether
		the network seems very sensitive to the parameters
		(e.g. unless the parameters are set to very specific
		values the network won't learn).

		I found that the single layer neural network worked the best. The reason for this is that i found the
		single layer to be much faster and easier to implement the the multi-layered network. I found that the 
		single layered architecture wasn't as sensitive as the multi-layered one, and i could use a larger alpha
		value. Even though the 2-layered system was a bit more accurate for the same threshold as the 1-layered
		system, the results were close enough that i think for this problem a 1-layered system would be sufficient.   

6 .- (10 marks) Describe how you would build a network to play the cat
	        and mouse game (move the mouse to help it survive).

		- Describe what the input is in terms of a vector of
		  values
		- Describe what the output layer looks like (how many
		  neurons and what they encode)
		- Describe the error function
		- How many layers should you use?

		I believe the input would be the Gamestate given as vectors i.e. the location of the cat, cheese etc. The Output layer would be the directions top, bottom, left, right indicating which way the mouse will move 
		next. The error function should be the output values as compared with the correct value, with the correct
		value being the mouse eating the cheese and surviving the cat. I think we should use 2-layered system, for increased accuracy.  

_____________________________________________________

Mark with an 'x' where appropriate. If something is only
working partially, briefly describe what works, what
doesn't work, or what problems exist.
	
        	Complete/Working	Partial		Not done

Logistic         X
 activation

Hyperbolic
 tangent         X
  activation

sigmoid_prime()  X

Feed-Forward     X				
 computation    				

Training by     X
 back-propagation


I haven't had time to finish test The logistics 2-layered neural network, but for the seeds it seems to be working, along with others. 

_____________________________________________________




Marking:

(5 marks) Sigmoid and Hyperbolic Tangent activation functions

(5 marks) Sigmoid prime function

(10 marks) Feed-forward computation

(20 marks) Backpropagation weight adjustments

(25 marks) Answers in this report

Total for A5:       / out of 65

